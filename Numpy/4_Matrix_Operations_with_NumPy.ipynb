{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OTPYGmez0kt"
      },
      "source": [
        "# Lesson 4: Matrix Operations with NumPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXGi20J10jES"
      },
      "source": [
        "### Matrix Multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq-BJoDi1Bnb"
      },
      "source": [
        "This colab notebook is gonna be a bit longer than the previous ones. So there is a need to know matrices and how they work in ML inorder to train any model!\n",
        "1.np.dot() :\n",
        "\n",
        "  * ***a) The np.dot()*** function performs the dot product of two arrays. For 2D arrays (matrices), it calculates the matrix product.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CLdPDWaFzyiy"
      },
      "outputs": [],
      "source": [
        "# Let's import numpy\n",
        "import numpy as np\n",
        "# you can import numpy with n or num or anything . Not necessarily np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idM7Cx2ozyf9",
        "outputId": "e4ea3729-1a97-45c3-9bd5-4fffb3a449e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[19 22]\n",
            " [43 50]]\n"
          ]
        }
      ],
      "source": [
        "a = np.array([[1,2],[3,4]])\n",
        "b = np.array([[5,6],[7,8]])\n",
        "result = np.dot(a,b)\n",
        "print(result)\n",
        "# Here every row element is multipled with every column element on the 2nd matrix and then added up\n",
        "# [(1*5)+(2*7)   (1*6)+(2*8)]\n",
        "# [(3*5)+(4*7)   (3*6)_(4*8)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZtB9V4M22xT"
      },
      "source": [
        "**Why it‚Äôs Important in ML:**\n",
        "\n",
        "Matrix multiplication is at the heart of deep learning. For example, multiplying weights with inputs in neural networks to compute layer outputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrOBReS827NA"
      },
      "source": [
        "* b) Using the ***@ Operator***\n",
        "It is a shorthand for matrix multiplication.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJIRZ3ZXzydT",
        "outputId": "ecab8925-7282-4ad9-e5f2-2e9696de62b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Multiplication Result (@ operator):\n",
            " [[19 22]\n",
            " [43 50]]\n"
          ]
        }
      ],
      "source": [
        "result_at = a @ b\n",
        "print(\"Matrix Multiplication Result (@ operator):\\n\", result_at)\n",
        "# We'll get the same result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDNzjVge3d45"
      },
      "source": [
        "**Why it‚Äôs Important in ML:**\n",
        "\n",
        "It provides a clean and concise way to represent matrix operations, crucial for large-scale computations in ML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEGWj_V83pOz"
      },
      "source": [
        "c) ***Element-wise Multiplication (*)***\n",
        "\n",
        "Multiplies corresponding elements of Two Matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B83xHNv-zya7",
        "outputId": "f59eef8d-e1a8-41f7-9806-4d37f2caff15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element-wise Multiplication Result:\n",
            " [[ 5 12]\n",
            " [21 32]]\n"
          ]
        }
      ],
      "source": [
        "element_wise = a * b\n",
        "print(\"Element-wise Multiplication Result:\\n\", element_wise)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogBV88jv4D37"
      },
      "source": [
        "**Why it‚Äôs Important in ML:**\n",
        "\n",
        "Used for operations like applying element-wise activation functions or manipulating specific parts of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "zesFYB4rzyYd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFc-fuLQ4I-p"
      },
      "source": [
        "### Inverse and Transpose of Matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjcR4FX74Oad"
      },
      "source": [
        "a) **Matrix Inverse (np.linalg.inv())**\n",
        "\n",
        "The inverse of a matrix\n",
        "ùê¥ satisfies\n",
        "ùê¥\n",
        "‚ãÖ\n",
        "ùê¥\n",
        "‚àí\n",
        "1\n",
        "=\n",
        "ùêº\n",
        "\n",
        "ùêº\n",
        "is the identity matrix where the diagonal elements are 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyL3cuvezyV7",
        "outputId": "b6bb9359-8a3c-46db-dd51-95c3030732b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Inverse:\n",
            " [[-2.   1. ]\n",
            " [ 1.5 -0.5]]\n",
            "Verification (C * C^-1):\n",
            " [[1.0000000e+00 0.0000000e+00]\n",
            " [8.8817842e-16 1.0000000e+00]]\n"
          ]
        }
      ],
      "source": [
        "# lets take a new matrix\n",
        "c = np.array([[1,2],[3,4]])\n",
        "inverse = np.linalg.inv(c)\n",
        "print(\"Matrix Inverse:\\n\", inverse)\n",
        "\n",
        "\n",
        "# Verify the result\n",
        "identity = np.dot(c, inverse)\n",
        "print(\"Verification (C * C^-1):\\n\", identity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9qvzZh76srk"
      },
      "source": [
        "If in case you are unfamiliar on [How to find A inverse](https://byjus.com/maths/find-inverse-of-matrix/)\n",
        "\n",
        "Ik that u are new to linalg which will see in the same notebook! Cool!\n",
        "\n",
        "**Why it‚Äôs Important in ML:**\n",
        "\n",
        "Matrix inverses are used to solve linear systems and in optimization problems like least-squares regression."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "eQFkOiV2SvLR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k23VnMcr7s5y"
      },
      "source": [
        "b) ***Matrix Transpose (np.transpose() or .T)*** :\n",
        "Flips a matrix over its diagonal, swapping rows with columns.\n",
        "\n",
        "**Why it‚Äôs Important in ML:**\n",
        "Transposes are useful when switching between row and column representations, e.g., in covariance matrices or backpropagation in neural networks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS3jdKwYzyTU",
        "outputId": "6c76ebb8-225a-4606-afd9-810f77a2964f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transpose of Matrix C:\n",
            " [[1 3]\n",
            " [2 4]]\n",
            "Transpose of Matrix C (using .T):\n",
            " [[1 3]\n",
            " [2 4]]\n"
          ]
        }
      ],
      "source": [
        "transpose = np.transpose(c)\n",
        "print(\"Transpose of Matrix C:\\n\", transpose)\n",
        "\n",
        "# Alternatively\n",
        "transpose_T = c.T\n",
        "print(\"Transpose of Matrix C (using .T):\\n\", transpose_T)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Matrix Methods\n",
        "\n"
      ],
      "metadata": {
        "id": "1snSSb5fMiRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "2ufd7cajS0ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eigen Values and Eigen Vectors\n",
        "\n"
      ],
      "metadata": {
        "id": "WzYUQp3vS_ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eigenvalues and eigenvectors are properties of square matrices. They play a role in dimensionality reduction (PCA).\n",
        "\n",
        "**Why it‚Äôs Important in ML:**\n",
        "\n",
        "Eigenvalues and eigenvectors are used in PCA for reducing the dimensionality of data while retaining its variance"
      ],
      "metadata": {
        "id": "85e_mDhOMkaI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "zdZhsrhZzyQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea1bf19-d686-49a4-8157-f7d8e77fe428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix D:\n",
            " [[2 0]\n",
            " [0 3]]\n",
            "Eigenvalues:\n",
            " [2. 3.]\n",
            "Eigenvectors:\n",
            " [[1. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "# Define a square matrix\n",
        "D = np.array([[2, 0], [0, 3]])\n",
        "\n",
        "# Compute eigenvalues and eigenvectors\n",
        "eigenvalues, eigenvectors = np.linalg.eig(D)\n",
        "print(\"Matrix D:\\n\", D)\n",
        "print(\"Eigenvalues:\\n\", eigenvalues)\n",
        "print(\"Eigenvectors:\\n\", eigenvectors)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solving Systems of Equations (np.linalg.solve)\n",
        "\n",
        "**Why it‚Äôs Important in ML:**\n",
        "\n",
        "Systems of equations arise in optimization, linear regression, and solving constraints in ML models."
      ],
      "metadata": {
        "id": "e9DQG8jmMzLf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-Byu1W4pzyOA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "190d6029-a4bd-4bd5-fbc7-0e04fa0b0ea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution of the System Ax = b:\n",
            " [2. 3.]\n"
          ]
        }
      ],
      "source": [
        "# Coefficient matrix (A) and constant matrix (b)\n",
        "A = np.array([[3, 1], [1, 2]])\n",
        "B = np.array([9, 8])\n",
        "\n",
        "# Solve for x\n",
        "solution = np.linalg.solve(A, B)\n",
        "print(\"Solution of the System Ax = b:\\n\", solution)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determinant of a Matrix (np.linalg.det())\n",
        "The determinant is a scalar value that provides insights into the properties of a matrix, such as whether it is invertible. If the determinant is\n",
        "0, the matrix is singular and cannot be inverted.\n",
        "\n",
        "**Why it‚Äôs Important in ML:**\n",
        "\n",
        "The determinant is used in algorithms like Gaussian elimination and calculating matrix inverses. In ML, it plays a role in transformations and evaluating model stability."
      ],
      "metadata": {
        "id": "3Z_eMwFuNPom"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8ZBs-JTnzyLe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56a01e28-0eef-4b18-f79b-62348f31adff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A:\n",
            " [[4 7]\n",
            " [2 6]]\n",
            "Determinant of A: 10.000000000000002\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define a square matrix\n",
        "A = np.array([[4, 7], [2, 6]])\n",
        "\n",
        "# Compute the determinant\n",
        "determinant = np.linalg.det(A)\n",
        "print(\"Matrix A:\\n\", A)\n",
        "print(\"Determinant of A:\", determinant)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Singular Value Decomposition (SVD) (np.linalg.svd())\n",
        "SVD decomposes a matrix\n",
        "ùê¥\n",
        "A into three matrices\n",
        "ùëà\n",
        ",\n",
        "Œ£\n",
        ",\n",
        " and\n",
        "ùëâ\n",
        "ùëá\n",
        "(v transpose)\n",
        "\n",
        " . It is widely used in dimensionality reduction and noise filtering.\n",
        "\n",
        " SVD decomposes a matrix\n",
        "ùêµ into three components:\n",
        "\n",
        "ùêµ\n",
        "=\n",
        "ùëà\n",
        "‚ãÖ\n",
        "Œ£\n",
        "‚ãÖ\n",
        "ùëâ\n",
        "ùëá\n",
        "\n",
        "Where:\n",
        "\n",
        "ùëà\n",
        ": A matrix of left singular vectors (orthogonal, size\n",
        "ùëö\n",
        "√ó\n",
        "ùëö\n",
        "m√óm).\n",
        "\n",
        "Œ£\n",
        ": A diagonal matrix containing singular values (non-negative, size\n",
        "ùëö\n",
        "√ó\n",
        "ùëõ\n",
        "m√ón).\n",
        "\n",
        "ùëâ\n",
        "ùëá\n",
        " : A matrix of right singular vectors (orthogonal, size\n",
        "ùëõ\n",
        "√ó\n",
        "ùëõ\n",
        "n√ón)."
      ],
      "metadata": {
        "id": "X4qjetqnNeF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The columns of\n",
        "ùëà are the eigenvectors of\n",
        "ùêµ\n",
        "‚ãÖ\n",
        "ùêµ\n",
        "ùëá\n",
        "\n",
        "* The singular values are the square roots of the eigenvalues of\n",
        "ùêµ\n",
        "‚ãÖ\n",
        "ùêµ\n",
        "ùëá\n",
        "  or\n",
        "ùêµ\n",
        "ùëá\n",
        "‚ãÖ\n",
        "ùêµ\n",
        "ingular values:\n",
        "Œ£\n",
        "=\n",
        "diag(sqrt\n",
        "(\n",
        "ùúÜ\n",
        "1\n",
        ",\n",
        "ùúÜ\n",
        "2\n",
        "))\n",
        "\n",
        "* Where\n",
        "ùúÜ\n",
        "1\n",
        ",\n",
        "ùúÜ\n",
        "2 are the eigenvalues of\n",
        "ùêµ\n",
        "ùëá\n",
        "‚ãÖ\n",
        "ùêµ\n",
        "\n",
        "* The rows of\n",
        "ùëâ\n",
        "ùëáare the eigenvectors of\n",
        "ùêµ\n",
        "ùëá\n",
        "‚ãÖ\n",
        "ùêµ\n"
      ],
      "metadata": {
        "id": "8dajYlMJOAQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why it‚Äôs Important in ML:**\n",
        "SVD is the backbone of Principal Component Analysis (PCA), used in data compression and feature extraction."
      ],
      "metadata": {
        "id": "kg9MVTJKO59Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DwNGOQkLzyJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba1a3494-7480-4d02-eb0e-3b3fb3ad8ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix B:\n",
            " [[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n",
            "U:\n",
            " [[-0.2298477   0.88346102  0.40824829]\n",
            " [-0.52474482  0.24078249 -0.81649658]\n",
            " [-0.81964194 -0.40189603  0.40824829]]\n",
            "Sigma:\n",
            " [9.52551809 0.51430058]\n",
            "V^T:\n",
            " [[-0.61962948 -0.78489445]\n",
            " [-0.78489445  0.61962948]]\n"
          ]
        }
      ],
      "source": [
        "# Define a matrix\n",
        "B = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Perform SVD\n",
        "U, Sigma, Vt = np.linalg.svd(B)\n",
        "print(\"Matrix B:\\n\", B)\n",
        "print(\"U:\\n\", U)\n",
        "print(\"Sigma:\\n\", Sigma)\n",
        "print(\"V^T:\\n\", Vt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Why SVD is Important in ML?***\n",
        "\n",
        "*Dimensionality Reduction:*\n",
        "\n",
        "* Used in PCA to reduce the feature space for better visualization and model performance.\n",
        "\n",
        "*Noise Filtering:*\n",
        "\n",
        "* Helps remove noise by reconstructing data using only significant singular values.\n",
        "\n",
        "*Matrix Approximation:*\n",
        "\n",
        "* Low-rank approximations are used in recommender systems."
      ],
      "metadata": {
        "id": "GnlwSwygQ-LA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QR Decomposition (np.linalg.qr())\n",
        "QR decomposition splits a matrix\n",
        "ùê¥ into an orthogonal matrix\n",
        "ùëÑ and an upper triangular matrix\n",
        "ùëÖ.\n",
        "\n",
        "**Why it‚Äôs Important in ML:**\n",
        "QR decomposition is used in solving linear regression problems and for numerical stability in computations."
      ],
      "metadata": {
        "id": "SK7yJTgVPJpc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "4_e6UWDGzyGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85006392-320f-4931-80bd-35a53f46f33e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix C:\n",
            " [[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n",
            "Q:\n",
            " [[-0.16903085  0.89708523]\n",
            " [-0.50709255  0.27602622]\n",
            " [-0.84515425 -0.34503278]]\n",
            "R:\n",
            " [[-5.91607978 -7.43735744]\n",
            " [ 0.          0.82807867]]\n"
          ]
        }
      ],
      "source": [
        "# Define a matrix\n",
        "C = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Perform QR decomposition\n",
        "Q, R = np.linalg.qr(C)\n",
        "print(\"Matrix C:\\n\", C)\n",
        "print(\"Q:\\n\", Q)\n",
        "print(\"R:\\n\", R)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fTFrzyjzxyJ"
      },
      "source": [
        "### Norm of a Matrix or Vector (np.linalg.norm())\n",
        "The norm measures the magnitude of a vector or matrix, such as the Euclidean norm or Frobenius norm.\n",
        "\n",
        "**Why it‚Äôs Important in ML:**\n",
        "\n",
        "Norms are used in regularization techniques like L2 regularization to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a vector and a matrix\n",
        "vector = np.array([3, 4])\n",
        "matrix = np.array([[1, 2], [3, 4]])\n",
        "\n",
        "# Compute norms\n",
        "vector_norm = np.linalg.norm(vector)\n",
        "matrix_norm = np.linalg.norm(matrix, 'fro')  # Frobenius norm\n",
        "print(\"Vector:\\n\", vector)\n",
        "print(\"Norm of Vector:\", vector_norm)\n",
        "print(\"Matrix:\\n\", matrix)\n",
        "print(\"Frobenius Norm of Matrix:\", matrix_norm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIo4n0lUPjaj",
        "outputId": "569ffe00-cbd0-485f-c04b-580d6b049247"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector:\n",
            " [3 4]\n",
            "Norm of Vector: 5.0\n",
            "Matrix:\n",
            " [[1 2]\n",
            " [3 4]]\n",
            "Frobenius Norm of Matrix: 5.477225575051661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rank of a Matrix (np.linalg.matrix_rank())\n",
        "The rank of a matrix is the dimension of the column space. It determines the number of linearly independent columns.\n",
        "\n",
        "**Why it‚Äôs Important in ML:**\n",
        "\n",
        "Matrix rank helps in identifying redundancy in data and is crucial for understanding the feasibility of linear systems."
      ],
      "metadata": {
        "id": "8exhPRZePqfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a matrix\n",
        "D = np.array([[1, 2], [2, 4]])\n",
        "\n",
        "# Compute the rank\n",
        "rank = np.linalg.matrix_rank(D)\n",
        "print(\"Matrix D:\\n\", D)\n",
        "print(\"Rank of D:\", rank)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZEfNcrVPlSj",
        "outputId": "caaec0ae-0088-4589-b681-1bb1c8fb0c66"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix D:\n",
            " [[1 2]\n",
            " [2 4]]\n",
            "Rank of D: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trace of a Matrix (np.trace())\n",
        "The trace is the sum of the diagonal elements of a square matrix.\n",
        "\n",
        "**Why it‚Äôs Important in ML:**\n",
        "\n",
        "The trace is used in optimization problems, such as in covariance matrix calculations in statistical ML."
      ],
      "metadata": {
        "id": "EQvkPAFOP1fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a square matrix\n",
        "E = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# Compute the trace\n",
        "trace = np.trace(E)\n",
        "print(\"Matrix E:\\n\", E)\n",
        "print(\"Trace of E:\", trace)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkSOMVG0PuRD",
        "outputId": "b659f392-1e20-4586-a98e-cbafd9f7a69b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix E:\n",
            " [[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "Trace of E: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solving Overdetermined or Underdetermined Systems (np.linalg.lstsq())\n",
        "\n",
        "This method finds the least-squares solution to\n",
        "ùê¥\n",
        "ùë•\n",
        "=\n",
        "ùëè when\n",
        "ùê¥\n",
        " is not square.\n",
        "\n",
        "**Why it‚Äôs Important in ML:**\n",
        "\n",
        "Least-squares solutions are used in regression models to find the best fit for data."
      ],
      "metadata": {
        "id": "8jAI8iFNQDks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Coefficient matrix and constants\n",
        "A = np.array([[1, 1], [1, 2], [1, 3]])\n",
        "b = np.array([6, 5, 7])\n",
        "\n",
        "# Solve using least squares\n",
        "x, residuals, rank, s = np.linalg.lstsq(A, b, rcond=None)\n",
        "print(\"Least-squares solution x:\", x)\n",
        "print(\"Residuals:\", residuals)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "870PjlYaP5K5",
        "outputId": "10c33bf6-a5c3-4f7f-adbb-75322bdb4de5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Least-squares solution x: [5.  0.5]\n",
            "Residuals: [1.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rank of a Matrix (np.linalg.matrix_rank)\n",
        "The rank of a matrix is the number of linearly independent rows or columns. It is essential in determining whether a matrix is full-rank, which is crucial for solving linear equations.\n",
        "\n",
        "**Why It's Important in ML?**\n",
        "\n",
        "Feature Engineering: Determines the dimensionality of the feature space.\n",
        "\n",
        "Data Consistency: Helps verify whether a dataset has redundant or dependent features."
      ],
      "metadata": {
        "id": "dPrSzkUUROUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define a matrix\n",
        "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# Compute the rank\n",
        "rank = np.linalg.matrix_rank(matrix)\n",
        "\n",
        "print(\"Matrix:\\n\", matrix)\n",
        "print(\"Rank of the matrix:\", rank)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD9VTUzTQQKU",
        "outputId": "58789831-7bb7-4ea2-ebb3-97ccc4b02ed8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix:\n",
            " [[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "Rank of the matrix: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moore-Penrose Pseudoinverse (np.linalg.pinv)\n",
        "The pseudoinverse is used when a matrix is not invertible (singular) but we still need an approximate solution for linear systems.\n",
        "\n",
        "**Why It's Important in ML?**\n",
        "\n",
        "* Linear Regression: Used to solve normal equations when\n",
        "(ùëã\n",
        "ùëá)(X transpose)\n",
        "ùëã where\n",
        " X is not invertible.\n",
        "\n",
        "* Overdetermined/Underdetermined Systems: Finds solutions when there are more equations than variables or vice versa.\n",
        "\n",
        "Learn more about this topic [here](https://www.geeksforgeeks.org/moore-penrose-pseudoinverse-mathematics/)\n"
      ],
      "metadata": {
        "id": "r20Xfv9qRY_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a non-square matrix\n",
        "A = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Compute the pseudoinverse\n",
        "pseudo_inv = np.linalg.pinv(A)\n",
        "\n",
        "print(\"Matrix A:\\n\", A)\n",
        "print(\"Pseudoinverse of A:\\n\", pseudo_inv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBP0VSGfRhPB",
        "outputId": "313306b7-3b58-4a69-e5e2-cf285b74a038"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A:\n",
            " [[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n",
            "Pseudoinverse of A:\n",
            " [[-1.33333333 -0.33333333  0.66666667]\n",
            " [ 1.08333333  0.33333333 -0.41666667]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QR Decomposition (np.linalg.qr)\n",
        "QR decomposition expresses a matrix\n",
        "ùê¥ as\n",
        "ùê¥\n",
        "=\n",
        "ùëÑ\n",
        "ùëÖ where\n",
        "ùëÑ is an orthogonal matrix and\n",
        "ùëÖ is an upper triangular matrix.\n",
        "\n",
        "**Why It's Important in ML?**\n",
        "\n",
        "Solving Linear Systems: QR decomposition is used in least squares problems.\n",
        "\n",
        "Eigenvalue Problems: A step in algorithms for eigenvalue computation."
      ],
      "metadata": {
        "id": "PYUYcr4ESEB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a matrix\n",
        "B = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Perform QR decomposition\n",
        "Q, R = np.linalg.qr(B)\n",
        "\n",
        "print(\"Matrix B:\\n\", B)\n",
        "print(\"Q (Orthogonal Matrix):\\n\", Q)\n",
        "print(\"R (Upper Triangular Matrix):\\n\", R)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PitXVQFzRh2J",
        "outputId": "087b8579-d589-43b2-ad0c-830d094c963a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix B:\n",
            " [[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n",
            "Q (Orthogonal Matrix):\n",
            " [[-0.16903085  0.89708523]\n",
            " [-0.50709255  0.27602622]\n",
            " [-0.84515425 -0.34503278]]\n",
            "R (Upper Triangular Matrix):\n",
            " [[-5.91607978 -7.43735744]\n",
            " [ 0.          0.82807867]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hadamard Product (Element-Wise Multiplication)\n"
      ],
      "metadata": {
        "id": "m_Z1I1g1SbLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two matrices\n",
        "F = np.array([[1, 2], [3, 4]])\n",
        "G = np.array([[5, 6], [7, 8]])\n",
        "\n",
        "# Compute the Hadamard product\n",
        "hadamard_product = F * G\n",
        "\n",
        "print(\"Matrix F:\\n\", F)\n",
        "print(\"Matrix G:\\n\", G)\n",
        "print(\"Hadamard Product:\\n\", hadamard_product)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AefZ2RHNSWhw",
        "outputId": "b646017e-bde8-43a8-b2a6-85add12e9fc5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix F:\n",
            " [[1 2]\n",
            " [3 4]]\n",
            "Matrix G:\n",
            " [[5 6]\n",
            " [7 8]]\n",
            "Hadamard Product:\n",
            " [[ 5 12]\n",
            " [21 32]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diagonal of a Matrix (np.diag)"
      ],
      "metadata": {
        "id": "2mvzhgyLSg0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract diagonal\n",
        "H = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "diagonal = np.diag(H)\n",
        "\n",
        "# Create diagonal matrix\n",
        "diag_matrix = np.diag([1, 2, 3])\n",
        "\n",
        "print(\"Matrix H:\\n\", H)\n",
        "print(\"Diagonal of H:\", diagonal)\n",
        "print(\"Diagonal Matrix:\\n\", diag_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hmUQG9CSeL4",
        "outputId": "7ad94110-9d63-47ae-c3c3-ffa3beffaf5a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix H:\n",
            " [[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "Diagonal of H: [1 5 9]\n",
            "Diagonal Matrix:\n",
            " [[1 0 0]\n",
            " [0 2 0]\n",
            " [0 0 3]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}