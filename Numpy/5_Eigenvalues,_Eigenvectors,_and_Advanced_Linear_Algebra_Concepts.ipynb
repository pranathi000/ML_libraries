{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson 5: Eigenvalues, Eigenvectors, and Advanced Linear Algebra Concepts"
      ],
      "metadata": {
        "id": "0q4tC8A-hVhQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "chncq6VBamlY"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why eigenvalues are imp in ML?\n",
        "* Dimensionality Reduction: Eigenvalues help in reducing the number of features (dimensions) in the dataset (e.g., Principal Component Analysis or PCA), which simplifies the model and speeds up training.\n",
        "\n",
        "* Understanding Data Structure: Eigenvalues help to understand the spread and orientation of data, aiding in better data preprocessing and visualization.\n",
        "\n",
        "* Stability of Models: In some models, eigenvalues indicate the stability of the model's behavior. For example, large or small eigenvalues can tell you if the model is overfitting or underfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "9lWqIXaKjpgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets define a square matrix\n",
        "A = np.array([[4,2],[1,3]])\n",
        "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
        "print(\"EigenValues : \",eigenvalues)\n",
        "print(\"EigenVectors : \",eigenvectors)\n",
        "# np.linalg.eig() is a simple method to calculate eigenValues and eigenVectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9hOwyX8aq03",
        "outputId": "7c80c0b4-669e-4081-8e7f-abfb03af933b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EigenValues :  [5. 2.]\n",
            "EigenVectors :  [[ 0.89442719 -0.70710678]\n",
            " [ 0.4472136   0.70710678]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Revising singular value decomposition\n",
        "# lets again define another matrix\n",
        "B = np.array([[1,2,3],[4,5,6]])\n",
        "U,sigma,VT = np.linalg.svd(B)\n",
        "print(\"U : \",U)\n",
        "print(\"Sigma : \",sigma)\n",
        "print(\"VT : \",VT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMQMP6JfbND9",
        "outputId": "409470d3-2c88-4c38-8aff-6c1eef9c440f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U :  [[-0.3863177  -0.92236578]\n",
            " [-0.92236578  0.3863177 ]]\n",
            "Sigma :  [9.508032   0.77286964]\n",
            "VT :  [[-0.42866713 -0.56630692 -0.7039467 ]\n",
            " [ 0.80596391  0.11238241 -0.58119908]\n",
            " [ 0.40824829 -0.81649658  0.40824829]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The QR decomposition can indeed be performed on non-square matrices\n",
        "# We have to make sure to have more rows than columns m>n m칑n:\n",
        "# QR decomposition factors a matrix A into:\n",
        "# A=Q.R\n",
        "# since we are coding it, it's not handy to explain mathematically. We have to apply Gram-Schmidt orthogonality to find Q\n",
        "# which takes much time to calculate with a pen and paper.\n",
        "C = np.array([[1, 2],\n",
        "              [3, 4],\n",
        "              [5, 6]])\n",
        "Q ,R = np.linalg.qr(C)\n",
        "print(\"Q : \",Q)\n",
        "print(\"R : \",R)\n",
        "# where Q: Orthogonal matrix.\n",
        "# 洧녠: Upper triangular matrix."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GPBGD8ocKyi",
        "outputId": "a0a2ccc5-66f3-49cc-9e59-4684d7d1ec92"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q :  [[-0.16903085  0.89708523]\n",
            " [-0.50709255  0.27602622]\n",
            " [-0.84515425 -0.34503278]]\n",
            "R :  [[-5.91607978 -7.43735744]\n",
            " [ 0.          0.82807867]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cholesky Decomposition\n",
        "# Define a symmetric positive-definite matrix\n",
        "# Lets define what a positive-definite matrix is : A matrix 洧냢 is symmetric if it is equal to its transpose\n",
        "# A matrix\n",
        "# 洧냢 is positive-definite if: (洧논洧녢)洧냢洧논>0 for마ll맕onzero맜ectors멇롐벺n",
        "\n",
        "\n",
        "D = np.array([[4, 2],\n",
        "              [2, 3]])\n",
        "L = np.linalg.cholesky(D)\n",
        "\n",
        "print(\"L:\\n\", L)\n",
        "# It speeds up matrix inversion and log-determinant calculations, which are common in probabilistic models and regression.\n",
        "#  Its numerical stability makes it a reliable choice in algorithms requiring precision.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDQwAbFTcv7s",
        "outputId": "f5c946ba-765d-4760-eeac-56c19c786b00"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L:\n",
            " [[2.         0.        ]\n",
            " [1.         1.41421356]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E = np.array([[1, 2, 3],\n",
        "              [4, 5, 6],\n",
        "              [7, 8, 9]])\n",
        "# Let's compute rank for this matrix\n",
        "rank = np.linalg.matrix_rank(E)\n",
        "print(\"Rank:\", rank)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhlpfLQSfb5g",
        "outputId": "2ddacbed-014b-4d0b-814c-6e22cbb2a10c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F = np.array([[1, 2],\n",
        "              [3, 4]])\n",
        "# note a point that finding trace is only applicable to square matrices since it is the sum of all diagonal elements.\n",
        "det = np.linalg.det(F)\n",
        "trace = np.trace(F)\n",
        "print(\"Determinant:\", det)\n",
        "print(\"Trace:\", trace)\n",
        "# In ML, calculating determinant is iseful to realise the issues in the model or in the data.\n",
        "# Positive det: Stable, invertible, desirable in most algorithms.\n",
        "# Negative det: Indicates problems like non-positive definiteness, leading to instability or errors in training."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVBwH8cRfp3N",
        "outputId": "4a311fd7-b90c-4c28-91fc-44d63baba9a3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Determinant: -2.0000000000000004\n",
            "Trace: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a matrix G (the one for which we want to find the dominant eigenvector)\n",
        "G = np.array([[2, 1],\n",
        "              [1, 3]])\n",
        "\n",
        "# Initial guess for the eigenvector (can be any vector)\n",
        "v = np.array([1, 1])\n",
        "\n",
        "# Repeat the process of multiplying by the matrix and normalizing the vector\n",
        "for _ in range(10):  # Repeat 10 times to get a more accurate result\n",
        "    v = np.dot(G, v)  # Multiply matrix G with the vector v\n",
        "    v = v / np.linalg.norm(v)  # Normalize the resulting vector to unit length\n",
        "\n",
        "# Print the final dominant eigenvector\n",
        "print(\"Dominant Eigenvector:\", v)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ63t5MjgEbk",
        "outputId": "d8785302-76cd-4470-e0d9-ba35109d9cd2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dominant Eigenvector: [0.52574439 0.8506426 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from scipy.linalg import expm\n",
        "\n",
        "# Define a matrix (example: a 2x2 matrix)\n",
        "A = np.array([[1, 2],\n",
        "              [3, 4]])\n",
        "\n",
        "# Calculate the matrix exponential of A\n",
        "A_exp = expm(A)\n",
        "\n",
        "# Print the result\n",
        "print(\"Matrix Exponential of A:\\n\", A_exp)\n",
        "\n",
        "# Goal: We want to compute the matrix exponential of a square matrix.\n",
        "# This is a generalization of the exponential function for matrices.\n",
        "# For a scalar 洧논, 洧 power 洧논 is a well-known function.\n",
        "# For matrices, we define the matrix exponential similarly, but it is computed using a power series expansion.\n",
        "# Why Matrix Exponentials are Useful in Machine Learning:\n",
        "\n",
        "# They are used in many advanced machine learning techniques, such as:\n",
        "# Solving differential equations that describe how a system evolves over time.\n",
        "# Stochastic processes, like Markov Chains or state transitions.\n",
        "# Continuous time models, such as in neural networks or reinforcement learning."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQvUPGBFhOVV",
        "outputId": "d6890a95-7cca-4264-86ba-94cbaed37126"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Exponential of A:\n",
            " [[ 51.9689562   74.73656457]\n",
            " [112.10484685 164.07380305]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "from scipy.linalg import null_space\n",
        "\n",
        "# Null Space: The null space of a matrix is the set of vectors that, when multiplied by the matrix, produce a zero vector.\n",
        "# Why is it useful?: The null space helps in understanding how many degrees of freedom exist when solving a system of equations.\n",
        "# If the null space has non-zero vectors, the system has infinitely many solutions.\n",
        "\n",
        "# Define a matrix (example: a 2x2 matrix)\n",
        "A = np.array([[2, 4],\n",
        "              [1, 2]])\n",
        "\n",
        "# Calculate the null space of A\n",
        "null_space_A = null_space(A)\n",
        "\n",
        "# null space in ML helps in reducing the complexity of models\n",
        "# and selecting features that matter, making the model more efficient and less prone to overfitting.\n",
        "\n",
        "# Print the result\n",
        "print(\"Null Space of A:\\n\", null_space_A)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKULpXjQihql",
        "outputId": "8d0d069e-67c1-4527-d978-da5f440567db"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null Space of A:\n",
            " [[-0.89442719]\n",
            " [ 0.4472136 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Condition Number in Machine Learning\n",
        "\n",
        "# 1. Import required libraries\n",
        "import numpy as np\n",
        "\n",
        "# 2. Define a matrix to work with\n",
        "A = np.array([[1, 2],\n",
        "              [3, 4]])\n",
        "\n",
        "# 3. Calculate the condition number of the matrix using np.linalg.cond()\n",
        "condition_number = np.linalg.cond(A)\n",
        "\n",
        "# 4. Display the condition number\n",
        "print(\"Condition Number of A:\", condition_number)\n",
        "\n",
        "# Explanation of the condition number\n",
        "#\n",
        "# - The condition number of a matrix tells us how sensitive the solution of a system of linear equations is to small changes in the input.\n",
        "# - If the condition number is high, the matrix is considered ill-conditioned, and small changes in the input can lead to large changes in the output.\n",
        "# - In machine learning, high condition numbers in models can cause instability, especially when dealing with noisy data.\n",
        "# - To deal with ill-conditioned problems, we can use regularization techniques such as Ridge or Lasso regression to stabilize the model.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW5ANkdCi3Yw",
        "outputId": "6f1cec08-2877-4361-c59b-a78e7a93359e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Condition Number of A: 14.933034373659268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalizing Data (Min-Max Scaling using NumPy)**\n",
        "\n",
        "(Min-Max Scaling):\n",
        "Min-Max Scaling transforms data into a fixed range, typically [0, 1]. It works by subtracting the minimum value of the feature and dividing by the range (difference between the maximum and minimum).\n",
        "\n",
        "forumula = Xscaled = (X-Xmin)/(Xmax-Xmin)\n",
        "\n",
        "*In ML:*\n",
        "\n",
        "* Consistent Range: It ensures that all features (input variables) are on the same scale, usually between 0 and 1. This makes it easier for ML algorithms to process the data effectively.\n",
        "\n",
        "* Improves Convergence: Many algorithms, especially gradient-based methods (like gradient descent in linear regression, neural networks, etc.), perform better when the data is normalized because it speeds up convergence.\n",
        "\n",
        "* Prevents Bias: If features have different ranges, algorithms may give more importance to the ones with larger values. Normalization ensures that no feature is biased due to its scale.\n"
      ],
      "metadata": {
        "id": "r7fCbKLjlRdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample data (could be a column in a dataset)\n",
        "data = np.array([10, 20, 30, 40, 50])\n",
        "\n",
        "# Step 1: Find the minimum and maximum values of the data\n",
        "min_value = np.min(data)\n",
        "max_value = np.max(data)\n",
        "\n",
        "# Step 2: Apply Min-Max Scaling\n",
        "scaled_data = (data - min_value) / (max_value - min_value)\n",
        "\n",
        "# Display results\n",
        "print(\"Original Data:\", data)\n",
        "print(\"Min Value:\", min_value)\n",
        "print(\"Max Value:\", max_value)\n",
        "print(\"Scaled Data:\", scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDeiZO82jLLe",
        "outputId": "dc4ea63d-e613-4c9f-875f-9914db37bb54"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data: [10 20 30 40 50]\n",
            "Min Value: 10\n",
            "Max Value: 50\n",
            "Scaled Data: [0.   0.25 0.5  0.75 1.  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Standardizing Data (Z-score Standardization)***\n",
        "\n",
        "Standardization rescales data to have a mean of 0 and a standard deviation of 1. It's often used for algorithms like Logistic Regression, KNN, and SVM."
      ],
      "metadata": {
        "id": "2S2hspUZl6AQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardizing data (Z-score standardization)\n",
        "data_standardized = (data - np.mean(data)) / np.std(data)\n",
        "\n",
        "print(\"Original Data:\", data)\n",
        "print(\"Standardized Data:\", data_standardized)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab9ob0h_mCYN",
        "outputId": "03e53ded-2d6b-402c-fcfa-4b0d6edcec52"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data: [10 20 30 40 50]\n",
            "Standardized Data: [-1.41421356 -0.70710678  0.          0.70710678  1.41421356]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***One-hot Encoding for Categorical Data***\n",
        "\n",
        "One-hot encoding is used to convert categorical variables into a form that could be provided to machine learning algorithms to do a better job in prediction.\n",
        "\n",
        "* Categories: We have a list of fruit categories that are not numeric.\n",
        "Unique Categories: We find all the unique fruit types (like 'apple', 'banana', etc.).\n",
        "\n",
        "* One-hot Encoding: We create a new array where each fruit category is represented as a vector with 1 in the position corresponding to that category and 0 elsewhere."
      ],
      "metadata": {
        "id": "lZ37R65OmSxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample categorical data (e.g., fruit categories)\n",
        "categories = ['apple', 'banana', 'apple', 'orange', 'banana']\n",
        "\n",
        "# Step 1: Create a unique set of categories (features)\n",
        "# This step finds all the unique categories in the data.\n",
        "unique_categories = np.unique(categories)\n",
        "\n",
        "# Step 2: Initialize an empty array for one-hot encoding\n",
        "# This creates a 2D array filled with zeros, with one row for each sample and one column for each unique category.\n",
        "one_hot_encoded = np.zeros((len(categories), len(unique_categories)))\n",
        "\n",
        "# Step 3: Fill in the one-hot encoding\n",
        "# This loop assigns a 1 in the corresponding column for each category in the original data.\n",
        "for i, category in enumerate(categories):\n",
        "    # np.where(unique_categories == category) finds the index of the category in the unique_categories array\n",
        "    one_hot_encoded[i, np.where(unique_categories == category)[0]] = 1\n",
        "\n",
        "# Print the results\n",
        "print(\"Original Categorical Data:\", categories)\n",
        "print(\"One-hot Encoded Data:\\n\", one_hot_encoded)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4SFxQ1hmEck",
        "outputId": "d8f5cf4d-cdb1-48b4-8099-0aca31193acf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Categorical Data: ['apple', 'banana', 'apple', 'orange', 'banana']\n",
            "One-hot Encoded Data:\n",
            " [[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most often we see nan values when training a model.\n",
        "In machine learning, missing data is a common issue. One way to handle this is by setting missing values to np.nan (Not a Number).\n",
        "\n"
      ],
      "metadata": {
        "id": "wiUNtv2xm6Ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data with missing values (np.nan)\n",
        "data_with_missing = np.array([1, 2, np.nan, 4, 5])\n",
        "\n",
        "# Masked data showing where values are missing (np.nan)\n",
        "print(\"Data with Missing Values:\", data_with_missing)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqV5bnx_megH",
        "outputId": "7136cdf0-68fa-46bb-fe7c-a31c4d1f60f7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data with Missing Values: [ 1.  2. nan  4.  5.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Filling Missing Values Using np.nan_to_num()***\n",
        "\n",
        "After identifying missing values, one way to handle them is by replacing np.nan with a specified value, such as 0 or the mean of the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "7KqgT4sHnJeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values (np.nan) with 0\n",
        "data_filled = np.nan_to_num(data_with_missing, nan=0)\n",
        "\n",
        "print(\"Data with Missing Values (filled):\", data_filled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R05ORt7HnHCG",
        "outputId": "bc287c8e-de8c-4371-82bd-c3854d18d4b4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data with Missing Values (filled): [1. 2. 0. 4. 5.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping Data for Machine Learning\n"
      ],
      "metadata": {
        "id": "ebJnj2ePneao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshaping Data for Models (2D Arrays for Supervised Learning, 3D Arrays for CNNs)\n",
        "\n",
        "* Machine learning algorithms, especially supervised learning models, typically require input data in a specific shape, often as a 2D array (samples 칑 features).\n",
        "\n",
        "* For supervised learning, data is typically in 2D (e.g., rows as data points and columns as features).\n",
        "\n",
        "* For Convolutional Neural Networks (CNNs), data is often 3D, representing height, width, and color channels (e.g., for image processing)."
      ],
      "metadata": {
        "id": "c0alyMHxnftQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for Reshaping to 2D for Supervised Learning\n",
        "# Sample 1D data (representing individual features of multiple data points)\n",
        "data_points = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "\n",
        "# Reshape to 2D array (5 samples with 2 features each)\n",
        "reshaped_data = data_points.reshape(5, 2)\n",
        "\n",
        "print(\"Original Data Shape:\", data_points.shape)\n",
        "print(\"Reshaped Data Shape:\", reshaped_data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuOZh1fvnQzc",
        "outputId": "26bdbc5f-6756-4b3f-bbff-f567b1d586ef"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data Shape: (10,)\n",
            "Reshaped Data Shape: (5, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Flattening 3D Arrays for Feeding into ML Models\n",
        "\n",
        "In machine learning, especially with CNNs, data is often in 3D arrays (e.g., for image data). These 3D arrays are then flattened into 1D arrays to feed into dense layers of a neural network."
      ],
      "metadata": {
        "id": "XFBJ8sxin_Lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 3D data (representing an image with height=2, width=3, channels=2)\n",
        "image_data = np.array([[[1, 2], [3, 4], [5, 6]],\n",
        "                       [[7, 8], [9, 10], [11, 12]]])\n",
        "\n",
        "# Flatten the 3D data to 1D for ML model input\n",
        "flattened_data = image_data.flatten()\n",
        "\n",
        "print(\"Original Data Shape:\", image_data.shape)\n",
        "print(\"Flattened Data Shape:\", flattened_data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiGAWS_9nzIy",
        "outputId": "7f4cb6b6-3cd3-4600-cbdc-6fe3a47e0c62"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data Shape: (2, 3, 2)\n",
            "Flattened Data Shape: (12,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Binomial Distribution (np.random.binomial())***\n",
        "\n",
        "The binomial distribution models the number of successes in a fixed number of independent trials, each with the same probability of success. It is commonly used for binary classification problems (like predicting if an email is spam or not)."
      ],
      "metadata": {
        "id": "01MPXcxO4O0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Binomial distribution: 10 trials, 0.5 probability of success, 1000 samples\n",
        "binomial_data = np.random.binomial(n=10, p=0.5, size=1000)\n",
        "\n",
        "# First 10 results\n",
        "print(\"First 10 Binomial Distribution samples:\", binomial_data[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msk12oPooJTI",
        "outputId": "980a88e5-ee07-45a0-d8b6-d42f6ce106f6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 Binomial Distribution samples: [4 5 3 9 5 7 5 3 4 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code simulates 1000 samples of a binomial distribution, where each sample is the number of successes in 10 trials with a 50% chance of success on each trial."
      ],
      "metadata": {
        "id": "xBpM2gfJ4aTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Poisson Distribution (np.random.poisson())***\n",
        "\n",
        "The Poisson distribution models the number of events happening in a fixed interval of time or space, where the events occur with a known constant mean rate and independently of each other. It is used in ML for problems like predicting the number of arrivals at a service station.\n",
        "\n"
      ],
      "metadata": {
        "id": "V7Q56_Ew4dJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Poisson distribution: mean = 3 events per hour, 1000 samples\n",
        "poisson_data = np.random.poisson(lam=3, size=1000)\n",
        "\n",
        "# First 10 results\n",
        "print(\"First 10 Poisson Distribution samples:\", poisson_data[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTt6U60s4W_G",
        "outputId": "6ba2d0a7-1f9f-4685-c941-c5a7ac42d656"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 Poisson Distribution samples: [2 4 4 4 1 2 4 2 4 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code simulates 1000 samples from a Poisson distribution, where the expected number of events in each interval is 3.\n"
      ],
      "metadata": {
        "id": "y9E21FMp4ksQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case if you are not aware of my previous colab notebooks, go take a look [here](https://github.com/pranathi000/ML_libraries/tree/main/Numpy)."
      ],
      "metadata": {
        "id": "n71zAUPO4sDC"
      }
    }
  ]
}