{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson 5: Eigenvalues, Eigenvectors, and Advanced Linear Algebra Concepts"
      ],
      "metadata": {
        "id": "0q4tC8A-hVhQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "chncq6VBamlY"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why eigenvalues are imp in ML?\n",
        "* Dimensionality Reduction: Eigenvalues help in reducing the number of features (dimensions) in the dataset (e.g., Principal Component Analysis or PCA), which simplifies the model and speeds up training.\n",
        "\n",
        "* Understanding Data Structure: Eigenvalues help to understand the spread and orientation of data, aiding in better data preprocessing and visualization.\n",
        "\n",
        "* Stability of Models: In some models, eigenvalues indicate the stability of the model's behavior. For example, large or small eigenvalues can tell you if the model is overfitting or underfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "9lWqIXaKjpgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets define a square matrix\n",
        "A = np.array([[4,2],[1,3]])\n",
        "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
        "print(\"EigenValues : \",eigenvalues)\n",
        "print(\"EigenVectors : \",eigenvectors)\n",
        "# np.linalg.eig() is a simple method to calculate eigenValues and eigenVectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9hOwyX8aq03",
        "outputId": "21a7d845-8c74-482f-a4f2-ff8ec9a660fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EigenValues :  [5. 2.]\n",
            "EigenVectors :  [[ 0.89442719 -0.70710678]\n",
            " [ 0.4472136   0.70710678]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Revising singular value decomposition\n",
        "# lets again define another matrix\n",
        "B = np.array([[1,2,3],[4,5,6]])\n",
        "U,sigma,VT = np.linalg.svd(B)\n",
        "print(\"U : \",U)\n",
        "print(\"Sigma : \",sigma)\n",
        "print(\"VT : \",VT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMQMP6JfbND9",
        "outputId": "f7667ae4-5ec8-4ba3-ac4c-f78c7d7ac0e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U :  [[-0.3863177  -0.92236578]\n",
            " [-0.92236578  0.3863177 ]]\n",
            "Sigma :  [9.508032   0.77286964]\n",
            "VT :  [[-0.42866713 -0.56630692 -0.7039467 ]\n",
            " [ 0.80596391  0.11238241 -0.58119908]\n",
            " [ 0.40824829 -0.81649658  0.40824829]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The QR decomposition can indeed be performed on non-square matrices\n",
        "# We have to make sure to have more rows than columns m>n m칑n:\n",
        "# QR decomposition factors a matrix A into:\n",
        "# A=Q.R\n",
        "# since we are coding it, it's not handy to explain mathematically. We have to apply Gram-Schmidt orthogonality to find Q\n",
        "# which takes much time to calculate with a pen and paper.\n",
        "C = np.array([[1, 2],\n",
        "              [3, 4],\n",
        "              [5, 6]])\n",
        "Q ,R = np.linalg.qr(C)\n",
        "print(\"Q : \",Q)\n",
        "print(\"R : \",R)\n",
        "# where Q: Orthogonal matrix.\n",
        "# 洧녠: Upper triangular matrix."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GPBGD8ocKyi",
        "outputId": "1281b79b-747f-4846-d1be-ee6e0439aac3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q :  [[-0.16903085  0.89708523]\n",
            " [-0.50709255  0.27602622]\n",
            " [-0.84515425 -0.34503278]]\n",
            "R :  [[-5.91607978 -7.43735744]\n",
            " [ 0.          0.82807867]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cholesky Decomposition\n",
        "# Define a symmetric positive-definite matrix\n",
        "# Lets define what a positive-definite matrix is : A matrix 洧냢 is symmetric if it is equal to its transpose\n",
        "# A matrix\n",
        "# 洧냢 is positive-definite if: (洧논洧녢)洧냢洧논>0 for마ll맕onzero맜ectors멇롐벺n",
        "\n",
        "\n",
        "D = np.array([[4, 2],\n",
        "              [2, 3]])\n",
        "L = np.linalg.cholesky(D)\n",
        "\n",
        "print(\"L:\\n\", L)\n",
        "# It speeds up matrix inversion and log-determinant calculations, which are common in probabilistic models and regression.\n",
        "#  Its numerical stability makes it a reliable choice in algorithms requiring precision.\n"
      ],
      "metadata": {
        "id": "TDQwAbFTcv7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "E = np.array([[1, 2, 3],\n",
        "              [4, 5, 6],\n",
        "              [7, 8, 9]])\n",
        "# Let's compute rank for this matrix\n",
        "rank = np.linalg.matrix_rank(E)\n",
        "print(\"Rank:\", rank)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhlpfLQSfb5g",
        "outputId": "ace298f7-4cf7-4399-867e-07c93e14540d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F = np.array([[1, 2],\n",
        "              [3, 4]])\n",
        "# note a point that finding trace is only applicable to square matrices since it is the sum of all diagonal elements.\n",
        "det = np.linalg.det(F)\n",
        "trace = np.trace(F)\n",
        "print(\"Determinant:\", det)\n",
        "print(\"Trace:\", trace)\n",
        "# In ML, calculating determinant is iseful to realise the issues in the model or in the data.\n",
        "# Positive det: Stable, invertible, desirable in most algorithms.\n",
        "# Negative det: Indicates problems like non-positive definiteness, leading to instability or errors in training."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVBwH8cRfp3N",
        "outputId": "531ac753-3d45-443f-ae84-3e7e8865d163"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Determinant: -2.0000000000000004\n",
            "Trace: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a matrix G (the one for which we want to find the dominant eigenvector)\n",
        "G = np.array([[2, 1],\n",
        "              [1, 3]])\n",
        "\n",
        "# Initial guess for the eigenvector (can be any vector)\n",
        "v = np.array([1, 1])\n",
        "\n",
        "# Repeat the process of multiplying by the matrix and normalizing the vector\n",
        "for _ in range(10):  # Repeat 10 times to get a more accurate result\n",
        "    v = np.dot(G, v)  # Multiply matrix G with the vector v\n",
        "    v = v / np.linalg.norm(v)  # Normalize the resulting vector to unit length\n",
        "\n",
        "# Print the final dominant eigenvector\n",
        "print(\"Dominant Eigenvector:\", v)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ63t5MjgEbk",
        "outputId": "2e03a7e3-b590-4116-a5c0-ccc1248cb2b2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dominant Eigenvector: [0.52574439 0.8506426 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from scipy.linalg import expm\n",
        "\n",
        "# Define a matrix (example: a 2x2 matrix)\n",
        "A = np.array([[1, 2],\n",
        "              [3, 4]])\n",
        "\n",
        "# Calculate the matrix exponential of A\n",
        "A_exp = expm(A)\n",
        "\n",
        "# Print the result\n",
        "print(\"Matrix Exponential of A:\\n\", A_exp)\n",
        "\n",
        "# Goal: We want to compute the matrix exponential of a square matrix.\n",
        "# This is a generalization of the exponential function for matrices.\n",
        "# For a scalar 洧논, 洧 power 洧논 is a well-known function.\n",
        "# For matrices, we define the matrix exponential similarly, but it is computed using a power series expansion.\n",
        "# Why Matrix Exponentials are Useful in Machine Learning:\n",
        "\n",
        "# They are used in many advanced machine learning techniques, such as:\n",
        "# Solving differential equations that describe how a system evolves over time.\n",
        "# Stochastic processes, like Markov Chains or state transitions.\n",
        "# Continuous time models, such as in neural networks or reinforcement learning."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQvUPGBFhOVV",
        "outputId": "3e592ad5-a9d6-47ee-9ac8-1488efa1e566"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Exponential of A:\n",
            " [[ 51.9689562   74.73656457]\n",
            " [112.10484685 164.07380305]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "from scipy.linalg import null_space\n",
        "\n",
        "# Null Space: The null space of a matrix is the set of vectors that, when multiplied by the matrix, produce a zero vector.\n",
        "# Why is it useful?: The null space helps in understanding how many degrees of freedom exist when solving a system of equations.\n",
        "# If the null space has non-zero vectors, the system has infinitely many solutions.\n",
        "\n",
        "# Define a matrix (example: a 2x2 matrix)\n",
        "A = np.array([[2, 4],\n",
        "              [1, 2]])\n",
        "\n",
        "# Calculate the null space of A\n",
        "null_space_A = null_space(A)\n",
        "\n",
        "# null space in ML helps in reducing the complexity of models\n",
        "# and selecting features that matter, making the model more efficient and less prone to overfitting.\n",
        "\n",
        "# Print the result\n",
        "print(\"Null Space of A:\\n\", null_space_A)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKULpXjQihql",
        "outputId": "89bc0301-c3d0-407a-a81d-6f31e02ef856"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null Space of A:\n",
            " [[-0.89442719]\n",
            " [ 0.4472136 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Condition Number in Machine Learning\n",
        "\n",
        "# 1. Import required libraries\n",
        "import numpy as np\n",
        "\n",
        "# 2. Define a matrix to work with\n",
        "A = np.array([[1, 2],\n",
        "              [3, 4]])\n",
        "\n",
        "# 3. Calculate the condition number of the matrix using np.linalg.cond()\n",
        "condition_number = np.linalg.cond(A)\n",
        "\n",
        "# 4. Display the condition number\n",
        "print(\"Condition Number of A:\", condition_number)\n",
        "\n",
        "# Explanation of the condition number\n",
        "#\n",
        "# - The condition number of a matrix tells us how sensitive the solution of a system of linear equations is to small changes in the input.\n",
        "# - If the condition number is high, the matrix is considered ill-conditioned, and small changes in the input can lead to large changes in the output.\n",
        "# - In machine learning, high condition numbers in models can cause instability, especially when dealing with noisy data.\n",
        "# - To deal with ill-conditioned problems, we can use regularization techniques such as Ridge or Lasso regression to stabilize the model.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW5ANkdCi3Yw",
        "outputId": "335e7293-faf1-456b-9c28-f7af8ccc166f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Condition Number of A: 14.933034373659268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EDeiZO82jLLe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}